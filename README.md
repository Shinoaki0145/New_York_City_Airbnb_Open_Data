# Airbnb NYC 2019 Price Prediction

Dá»± Ã¡n phÃ¢n tÃ­ch vÃ  dá»± Ä‘oÃ¡n giÃ¡ thuÃª phÃ²ng Airbnb táº¡i New York City nÄƒm 2019. Äiá»ƒm Ä‘áº·c biá»‡t cá»§a dá»± Ã¡n lÃ  viá»‡c **tá»± xÃ¢y dá»±ng (implement from scratch)** cÃ¡c thuáº­t toÃ¡n Machine Learning cá»‘t lÃµi (Linear Regression, Lasso Regression) sá»­ dá»¥ng thÆ° viá»‡n **NumPy**, thay vÃ¬ phá»¥ thuá»™c vÃ o cÃ¡c thÆ° viá»‡n cáº¥p cao nhÆ° Scikit-learn.

## ğŸ“‹ Má»¥c lá»¥c
1. [Giá»›i thiá»‡u](#giá»›i-thiá»‡u)
2. [Dataset](#dataset)
3. [Method](#method)
4. [Installation & Setup](#installation--setup)
5. [Usage](#usage)
6. [Results](#results)
7. [Project Structure](#project-structure)
8. [Challenges & Solutions](#challenges--solutions)
9. [Future Improvements](#future-improvements)
10. [Contributors](#contributors)
11. [License](#license)

---

## ğŸŒŸ Giá»›i thiá»‡u

### 1. MÃ´ táº£ bÃ i toÃ¡n
Dá»± Ã¡n táº­p trung vÃ o viá»‡c xÃ¢y dá»±ng mÃ´ hÃ¬nh Machine Learning Ä‘á»ƒ dá»± Ä‘oÃ¡n giÃ¡ niÃªm yáº¿t (**listing price**) cá»§a cÃ¡c cÄƒn há»™/phÃ²ng Airbnb táº¡i New York City nÄƒm 2019.
- **Input:** CÃ¡c Ä‘áº·c Ä‘iá»ƒm cá»§a cÄƒn há»™ nhÆ° vá»‹ trÃ­ (quáº­n, khu vá»±c), loáº¡i phÃ²ng (nguyÃªn cÄƒn, phÃ²ng riÃªng), sá»‘ Ä‘Ãªm tá»‘i thiá»ƒu, sá»‘ lÆ°á»£ng Ä‘Ã¡nh giÃ¡, v.v.
- **Output:** GiÃ¡ thuÃª phÃ²ng (biáº¿n liÃªn tá»¥c).
- **Loáº¡i bÃ i toÃ¡n:** Supervised Learning - Regression (Há»“i quy tuyáº¿n tÃ­nh).

### 2. Äá»™ng lá»±c & á»¨ng dá»¥ng thá»±c táº¿
Viá»‡c Ä‘á»‹nh giÃ¡ phÃ²ng (Dynamic Pricing) lÃ  má»™t thÃ¡ch thá»©c lá»›n trong ná»n kinh táº¿ chia sáº»:
- **Äá»‘i vá»›i Chá»§ nhÃ  (Hosts):** GiÃºp há» Ä‘Æ°a ra má»©c giÃ¡ cáº¡nh tranh Ä‘á»ƒ tá»‘i Ä‘a hÃ³a lá»£i nhuáº­n vÃ  tá»· lá»‡ láº¥p Ä‘áº§y (occupancy rate), trÃ¡nh viá»‡c Ä‘á»‹nh giÃ¡ quÃ¡ cao (khÃ´ng ai thuÃª) hoáº·c quÃ¡ tháº¥p (máº¥t doanh thu).
- **Äá»‘i vá»›i KhÃ¡ch thuÃª (Guests):** Cung cáº¥p tham chiáº¿u Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ xem má»™t má»©c giÃ¡ cÃ³ há»£p lÃ½ hay khÃ´ng, giÃºp há» tÃ¬m Ä‘Æ°á»£c cÃ¡c "deal" tá»‘t hoáº·c trÃ¡nh bá»‹ "há»›".
- **Äá»‘i vá»›i Ná»n táº£ng:** Gá»£i Ã½ giÃ¡ tá»± Ä‘á»™ng giÃºp cáº£i thiá»‡n tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng vÃ  cÃ¢n báº±ng cung cáº§u thá»‹ trÆ°á»ng.

### 3. Má»¥c tiÃªu cá»¥ thá»ƒ
Dá»± Ã¡n khÃ´ng chá»‰ dá»«ng láº¡i á»Ÿ viá»‡c gá»i thÆ° viá»‡n cÃ³ sáºµn, mÃ  hÆ°á»›ng tá»›i cÃ¡c má»¥c tiÃªu chuyÃªn sÃ¢u:
- **Vá» Ká»¹ thuáº­t:** Tá»± cÃ i Ä‘áº·t (implement from scratch) cÃ¡c thuáº­t toÃ¡n **Linear Regression** vÃ  **Lasso Regression** chá»‰ sá»­ dá»¥ng **NumPy**. Äiá»u nÃ y giÃºp náº¯m vá»¯ng báº£n cháº¥t toÃ¡n há»c (Matrix Calculus, Gradient Descent, Coordinate Descent).
- **Vá» Dá»¯ liá»‡u:** XÃ¢y dá»±ng quy trÃ¬nh xá»­ lÃ½ dá»¯ liá»‡u (Data Pipeline) hoÃ n chá»‰nh tá»« lÃ m sáº¡ch, xá»­ lÃ½ nhiá»…u, Ä‘áº¿n trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng (Feature Engineering) nÃ¢ng cao nhÆ° Target Encoding.
- **Vá» Káº¿t quáº£:** XÃ¢y dá»±ng mÃ´ hÃ¬nh cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cháº¥p nháº­n Ä‘Æ°á»£c (RÂ² > 0.5) vÃ  quan trá»ng hÆ¡n lÃ  kháº£ nÄƒng **giáº£i thÃ­ch (interpretability)** - chá»‰ ra Ä‘Æ°á»£c yáº¿u tá»‘ nÃ o tÃ¡c Ä‘á»™ng máº¡nh nháº¥t Ä‘áº¿n giÃ¡ phÃ²ng táº¡i NYC.

---

## ğŸ“Š Dataset

### 1. Nguá»“n dá»¯ liá»‡u
- **Nguá»“n:** [New York City Airbnb Open Data (Kaggle)](https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data)
- **KÃ­ch thÆ°á»›c:** ~49,000 dÃ²ng dá»¯ liá»‡u.

### 2. MÃ´ táº£ cÃ¡c features
- **Categorical:** `neighbourhood_group` (5 quáº­n), `neighbourhood` (200+ khu vá»±c), `room_type` (3 loáº¡i).
- **Numerical:** `latitude`, `longitude`, `minimum_nights`, `number_of_reviews`, `reviews_per_month`, `calculated_host_listings_count`, `availability_365`.
- **Target:** `price` (USD).

### 3. Äáº·c Ä‘iá»ƒm dá»¯ liá»‡u & EDA
DÆ°á»›i Ä‘Ã¢y lÃ  má»™t sá»‘ biá»ƒu Ä‘á»“ quan trá»ng tá»« quÃ¡ trÃ¬nh khÃ¡m phÃ¡ dá»¯ liá»‡u:

#### a. PhÃ¢n phá»‘i giÃ¡ (Price Distribution)
Pháº§n lá»›n cÃ¡c listing cÃ³ giÃ¡ dÆ°á»›i $200/Ä‘Ãªm. Biá»ƒu Ä‘á»“ bÃªn dÆ°á»›i hiá»ƒn thá»‹ phÃ¢n phá»‘i giÃ¡ cho cÃ¡c cÄƒn há»™ <= $500.
![Price Distribution](https://github.com/user-attachments/assets/2d8bf7ec-274a-47bf-acfc-26a86090b8b8)

#### b. PhÃ¢n bá»‘ Ä‘á»‹a lÃ½ (Geographic Distribution)
CÃ¡c listing táº­p trung dÃ y Ä‘áº·c táº¡i Manhattan vÃ  Brooklyn. MÃ u sáº¯c thá»ƒ hiá»‡n má»©c giÃ¡ (Ä‘á»/vÃ ng lÃ  giÃ¡ cao).
![Geographic Map](https://github.com/user-attachments/assets/5d263ddb-1902-49ce-ae12-2149b2996e70)

#### c. GiÃ¡ theo loáº¡i phÃ²ng (Price by Room Type)
"Entire home/apt" cÃ³ má»©c giÃ¡ cao nháº¥t vÃ  biáº¿n Ä‘á»™ng lá»›n nháº¥t, trong khi "Shared room" cÃ³ giÃ¡ tháº¥p nháº¥t.
![Room Type Price](images/11.png)

#### d. Sá»± thá»‘ng trá»‹ thá»‹ trÆ°á»ng (Market Domination)
Má»™t sá»‘ khu vá»±c táº¡i Manhattan bá»‹ chi phá»‘i máº¡nh máº½ bá»Ÿi cÃ¡c "Top Hosts" (nhá»¯ng ngÆ°á»i quáº£n lÃ½ nhiá»u listing), cho tháº¥y tÃ­nh cháº¥t thÆ°Æ¡ng máº¡i hÃ³a cao.
![Market Domination](images/18.png)

#### e. TÆ°Æ¡ng quan biáº¿n sá»‘ (Correlation Matrix)
Biá»ƒu Ä‘á»“ nhiá»‡t thá»ƒ hiá»‡n má»‘i tÆ°Æ¡ng quan giá»¯a cÃ¡c biáº¿n sá»‘. CÃ¡c biáº¿n sá»‘ Ã­t cÃ³ sá»± tÆ°Æ¡ng quan tuyáº¿n tÃ­nh máº¡nh vá»›i nhau, ngoáº¡i trá»« `number_of_reviews` vÃ  `reviews_per_month`.
![Correlation Matrix](images/13.png)

#### f. PhÃ¢n bá»‘ máº­t Ä‘á»™ giÃ¡ theo khu vá»±c (Price Density by Neighbourhood)
Biá»ƒu Ä‘á»“ Violin cho tháº¥y máº­t Ä‘á»™ phÃ¢n phá»‘i giÃ¡ táº¡i Manhattan rá»™ng hÆ¡n vÃ  cÃ³ Ä‘uÃ´i dÃ i hÆ¡n (nhiá»u listing giÃ¡ cao) so vá»›i cÃ¡c quáº­n khÃ¡c nhÆ° Queens hay Bronx.
![Price Density](images/8.png)

#### g. Tá»« khÃ³a phá»• biáº¿n trong tÃªn listing (Top Words)
CÃ¡c tá»« khÃ³a xuáº¥t hiá»‡n nhiá»u nháº¥t trong tÃªn phÃ²ng thÆ°á»ng liÃªn quan Ä‘áº¿n vá»‹ trÃ­ ("Manhattan", "Brooklyn", "Williamsburg") vÃ  Ä‘áº·c Ä‘iá»ƒm phÃ²ng ("Private", "Room", "Cozy", "Spacious").
![Top Words](images/23.png)

---

## ğŸ›  Method

### 1. Quy trÃ¬nh xá»­ lÃ½ dá»¯ liá»‡u (Data Preprocessing Pipeline)
Quy trÃ¬nh Ä‘Æ°á»£c thá»±c hiá»‡n tuáº§n tá»± Ä‘á»ƒ Ä‘áº£m báº£o dá»¯ liá»‡u sáº¡ch vÃ  giÃ u thÃ´ng tin cho mÃ´ hÃ¬nh:

#### a. Data Cleaning (LÃ m sáº¡ch)
- **Missing Values:**
  - `reviews_per_month`: NaN Ä‘Æ°á»£c Ä‘iá»n báº±ng 0 (giáº£ Ä‘á»‹nh khÃ´ng cÃ³ review nghÄ©a lÃ  0 review/thÃ¡ng).
  - `name`, `host_name`: CÃ¡c trÆ°á»ng vÄƒn báº£n thiáº¿u Ä‘Æ°á»£c Ä‘iá»n placeholder hoáº·c bá» qua vÃ¬ khÃ´ng dÃ¹ng trá»±c tiáº¿p.
- **Outlier Removal:**
  - Loáº¡i bá» cÃ¡c listing cÃ³ `price = 0` (lá»—i dá»¯ liá»‡u).
  - Loáº¡i bá» cÃ¡c listing cÃ³ giÃ¡ quÃ¡ cao (vÃ­ dá»¥ > $10,000) Ä‘á»ƒ trÃ¡nh lÃ m lá»‡ch mÃ´ hÃ¬nh Linear.

#### b. Feature Engineering (Táº¡o Ä‘áº·c trÆ°ng)
- **Log Transformation:**
  - Biáº¿n má»¥c tiÃªu `price` cÃ³ phÃ¢n phá»‘i lá»‡ch pháº£i (right-skewed). Ãp dá»¥ng `log(1 + price)` Ä‘á»ƒ Ä‘Æ°a vá» dáº¡ng gáº§n phÃ¢n phá»‘i chuáº©n, giÃºp mÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n.
- **Geospatial Features:**
  - TÃ­nh khoáº£ng cÃ¡ch tá»« cÄƒn há»™ Ä‘áº¿n trung tÃ¢m NYC (Times Square) sá»­ dá»¥ng cÃ´ng thá»©c **Haversine** dá»±a trÃªn vÄ© Ä‘á»™ (`latitude`) vÃ  kinh Ä‘á»™ (`longitude`).
- **Binning:**
  - Biáº¿n `minimum_nights` Ä‘Æ°á»£c chia nhÃ³m thÃ nh: `short_term` (<7 ngÃ y), `weekly` (7-30 ngÃ y), `monthly` (>30 ngÃ y) Ä‘á»ƒ báº¯t Ä‘Æ°á»£c cÃ¡c hÃ nh vi thuÃª khÃ¡c nhau.

#### c. Encoding (MÃ£ hÃ³a biáº¿n phÃ¢n loáº¡i)
- **One-Hot Encoding:** Ãp dá»¥ng cho biáº¿n cÃ³ Ã­t giÃ¡ trá»‹ (`neighbourhood_group`, `room_type`).
- **Target Encoding (with Smoothing):**
  - Ãp dá»¥ng cho biáº¿n `neighbourhood` (hÆ¡n 200 giÃ¡ trá»‹). Thay vÃ¬ táº¡o 200 cá»™t má»›i (gÃ¢y thÆ°a dá»¯ liá»‡u), ta thay tháº¿ tÃªn khu vá»±c báº±ng giÃ¡ trung bÃ¬nh cá»§a khu vá»±c Ä‘Ã³.
  - **Smoothing:** Äá»ƒ trÃ¡nh overfitting vá»›i cÃ¡c khu vá»±c cÃ³ Ã­t dá»¯ liá»‡u, cÃ´ng thá»©c Ä‘Æ°á»£c Ä‘iá»u chá»‰nh:
    $$ S_i = \lambda \times \mu_i + (1 - \lambda) \times \mu_{global} $$
    Trong Ä‘Ã³ $\mu_i$ lÃ  giÃ¡ trung bÃ¬nh khu vá»±c $i$, $\mu_{global}$ lÃ  giÃ¡ trung bÃ¬nh toÃ n táº­p dá»¯ liá»‡u.

#### d. Scaling (Chuáº©n hÃ³a)
- Sá»­ dá»¥ng **Min-Max Scaling** Ä‘á»ƒ Ä‘Æ°a táº¥t cáº£ cÃ¡c biáº¿n sá»‘ vá» khoáº£ng $[0, 1]$. Äiá»u nÃ y Ä‘áº·c biá»‡t quan trá»ng vá»›i Lasso Regression vÃ¬ thuáº­t toÃ¡n nÃ y nháº¡y cáº£m vá»›i Ä‘á»™ lá»›n cá»§a dá»¯ liá»‡u (scale-sensitive).

### 2. Thuáº­t toÃ¡n & CÃ i Ä‘áº·t (Algorithms & Implementation)

Dá»± Ã¡n tá»± cÃ i Ä‘áº·t cÃ¡c class `LinearRegression` vÃ  `Lasso` káº¿ thá»«a cáº¥u trÃºc tÆ°Æ¡ng tá»± Scikit-learn (`fit`, `predict`).

#### a. Linear Regression (Há»“i quy tuyáº¿n tÃ­nh)
**Má»¥c tiÃªu:** TÃ¬m vector trá»ng sá»‘ $\beta$ sao cho tá»•ng bÃ¬nh phÆ°Æ¡ng sai sá»‘ (RSS) lÃ  nhá» nháº¥t:
$$ J(\beta) = ||y - X\beta||_2^2 = \sum_{i=1}^{n} (y_i - x_i^T\beta)^2 $$

**Giáº£i phÃ¡p (Closed-form Solution):**
Nghiá»‡m tá»‘i Æ°u Ä‘Æ°á»£c tÃ­nh báº±ng phÆ°Æ¡ng trÃ¬nh chuáº©n (Normal Equation):
$$ \hat{\beta} = (X^T X)^{-1} X^T y $$

**Implementation vá»›i NumPy:**
Thay vÃ¬ tÃ­nh nghá»‹ch Ä‘áº£o ma tráº­n $(X^T X)^{-1}$ (tá»‘n kÃ©m vÃ  kÃ©m á»•n Ä‘á»‹nh), ta giáº£i há»‡ phÆ°Æ¡ng trÃ¬nh tuyáº¿n tÃ­nh $A\beta = b$:
- Äáº·t $A = X^T X$ vÃ  $b = X^T y$.
- Sá»­ dá»¥ng hÃ m tá»‘i Æ°u cá»§a NumPy:
  ```python
  # self.weights = np.linalg.inv(X.T @ X) @ X.T @ y  <-- KhÃ´ng nÃªn dÃ¹ng
  self.weights = np.linalg.solve(X.T @ X, X.T @ y) # <-- Tá»‘i Æ°u hÆ¡n
  ```

#### b. Lasso Regression (L1 Regularization)
**Má»¥c tiÃªu:** Tá»‘i thiá»ƒu hÃ³a hÃ m máº¥t mÃ¡t cÃ³ thÃªm thÃ nh pháº§n Ä‘iá»u chuáº©n L1 (giÃºp triá»‡t tiÃªu cÃ¡c trá»ng sá»‘ khÃ´ng quan trá»ng vá» 0):
$$ J(\beta) = \frac{1}{2n} ||y - X\beta||_2^2 + \alpha ||\beta||_1 $$

**Giáº£i phÃ¡p (Coordinate Descent):**
VÃ¬ hÃ m L1 khÃ´ng cÃ³ Ä‘áº¡o hÃ m táº¡i 0, ta khÃ´ng dÃ¹ng Gradient Descent thÃ´ng thÆ°á»ng mÃ  dÃ¹ng **Coordinate Descent**. Ta tá»‘i Æ°u tá»«ng trá»ng sá»‘ $\beta_j$ trong khi giá»¯ cá»‘ Ä‘á»‹nh cÃ¡c trá»ng sá»‘ $\beta_{k \neq j}$.

CÃ´ng thá»©c cáº­p nháº­t cho $\beta_j$:
$$ \beta_j = S(\rho_j, \alpha) $$
Trong Ä‘Ã³:
- $\rho_j = \sum_{i=1}^{n} x_{ij} (y_i - \sum_{k \neq j} x_{ik}\beta_k)$ (tÆ°Æ¡ng quan giá»¯a biáº¿n $j$ vÃ  pháº§n dÆ°).
- $S(z, \alpha)$ lÃ  toÃ¡n tá»­ **Soft Thresholding**:
  $$ S(z, \alpha) = \begin{cases} z - \alpha & \text{náº¿u } z > \alpha \\ z + \alpha & \text{náº¿u } z < -\alpha \\ 0 & \text{náº¿u } |z| \le \alpha \end{cases} $$

**Implementation vá»›i NumPy:**
- TÃ­nh toÃ¡n trÆ°á»›c cÃ¡c giÃ¡ trá»‹ khÃ´ng Ä‘á»•i Ä‘á»ƒ tÄƒng tá»‘c vÃ²ng láº·p.
- Sá»­ dá»¥ng vectorization Ä‘á»ƒ tÃ­nh dá»± Ä‘oÃ¡n $\hat{y}$ vÃ  pháº§n dÆ° $r = y - \hat{y}$.
- Cáº­p nháº­t trá»ng sá»‘ láº·p Ä‘i láº·p láº¡i cho Ä‘áº¿n khi há»™i tá»¥ (sai sá»‘ thay Ä‘á»•i nhá» hÆ¡n ngÆ°á»¡ng `tol`).

---

## âš™ï¸ Installation & Setup

### YÃªu cáº§u há»‡ thá»‘ng
- Python 3.8+
- ThÆ° viá»‡n: NumPy, Matplotlib, Seaborn (xem `requirements.txt`)

### CÃ i Ä‘áº·t mÃ´i trÆ°á»ng
```bash
pip install -r requirements.txt
```

---

## ğŸš€ Usage

### HÆ°á»›ng dáº«n cÃ¡ch cháº¡y tá»«ng pháº§n
1.  **KhÃ¡m phÃ¡ dá»¯ liá»‡u (EDA):**
    - Má»Ÿ vÃ  cháº¡y `notebooks/01_data_exploration.ipynb` Ä‘á»ƒ xem phÃ¢n tÃ­ch phÃ¢n phá»‘i, báº£n Ä‘á»“ vÃ  tÆ°Æ¡ng quan.
2.  **Tiá»n xá»­ lÃ½ dá»¯ liá»‡u (Preprocessing):**
    - Cháº¡y `notebooks/02_preprocessing.ipynb` Ä‘á»ƒ thá»±c hiá»‡n lÃ m sáº¡ch, mÃ£ hÃ³a vÃ  chuáº©n hÃ³a dá»¯ liá»‡u. Káº¿t quáº£ sáº½ Ä‘Æ°á»£c lÆ°u vÃ o `data/processed/`.
3.  **Huáº¥n luyá»‡n & ÄÃ¡nh giÃ¡ (Modeling):**
    - Cháº¡y `notebooks/03_modeling.ipynb` Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh Linear/Lasso vÃ  xem káº¿t quáº£ chi tiáº¿t.

---

## ğŸ“ˆ Results

### 1. Káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c (Metrics)
Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ trÃªn táº­p Test (20% dá»¯ liá»‡u) sau khi tá»‘i Æ°u hÃ³a tham sá»‘:

| Metric | Train Set | Test Set | Cross-Validation (Mean) | Ã nghÄ©a |
|--------|-----------|----------|-------------------------|---------|
| **RÂ² Score** | **0.554** | **0.546** | 0.553 (Â±0.011) | MÃ´ hÃ¬nh giáº£i thÃ­ch Ä‘Æ°á»£c ~54.6% sá»± biáº¿n thiÃªn cá»§a giÃ¡. |
| **RMSE** | 0.462 | 0.468 | 0.462 (Â±0.011) | Sai sá»‘ trung bÃ¬nh (trÃªn thang log). |
| **MAE** | 0.335 | 0.334 | 0.335 (Â±0.005) | Sai sá»‘ tuyá»‡t Ä‘á»‘i trung bÃ¬nh. |

> **Nháº­n xÃ©t:** Chá»‰ sá»‘ RÂ² giá»¯a táº­p Train vÃ  Test chÃªnh lá»‡ch ráº¥t nhá» (0.008), cho tháº¥y mÃ´ hÃ¬nh **khÃ´ng bá»‹ Overfitting** vÃ  cÃ³ kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a tá»‘t.

### 2. Trá»±c quan hÃ³a káº¿t quáº£ (Visualizations)

#### a. Cross-Validation Scores
Biá»ƒu Ä‘á»“ cho tháº¥y sá»± á»•n Ä‘á»‹nh cá»§a mÃ´ hÃ¬nh qua 5 láº§n chia dá»¯ liá»‡u (5-fold CV).
![CV Scores](images/24.png)

#### b. Actual vs Predicted
Biá»ƒu Ä‘á»“ phÃ¢n tÃ¡n giá»¯a giÃ¡ thá»±c táº¿ vÃ  giÃ¡ dá»± Ä‘oÃ¡n. CÃ¡c Ä‘iá»ƒm táº­p trung quanh Ä‘Æ°á»ng chÃ©o Ä‘á» ($y=x$) cho tháº¥y Ä‘á»™ chÃ­nh xÃ¡c khÃ¡ tá»‘t, tuy nhiÃªn mÃ´ hÃ¬nh cÃ³ xu hÆ°á»›ng dá»± Ä‘oÃ¡n tháº¥p hÆ¡n thá»±c táº¿ á»Ÿ phÃ¢n khÃºc giÃ¡ ráº¥t cao (luxury).
![Actual vs Predicted](images/25.png)

#### c. Residuals Analysis
PhÃ¢n phá»‘i cá»§a pháº§n dÆ° (Residuals) gáº§n chuáº©n (Normal distribution) vÃ  táº­p trung quanh 0, cho tháº¥y mÃ´ hÃ¬nh khÃ´ng bá»‹ bias lá»›n.
![Residuals](images/26.png)

#### d. Feature Importance
CÃ¡c yáº¿u tá»‘ áº£nh hÆ°á»Ÿng máº¡nh nháº¥t Ä‘áº¿n giÃ¡ phÃ²ng.
- **TÄƒng giÃ¡:** Entire home/apt, Manhattan, cÃ¡c khu vá»±c Ä‘áº¯t Ä‘á».
- **Giáº£m giÃ¡:** Shared room, Bronx, cÃ¡c khu vá»±c xa trung tÃ¢m.
![Feature Importance](images/27.png)

### 3. So sÃ¡nh vÃ  phÃ¢n tÃ­ch

#### PhÃ¢n tÃ­ch cÃ¡c yáº¿u tá»‘ áº£nh hÆ°á»Ÿng (Feature Importance)
Dá»±a trÃªn trá»ng sá»‘ ($\beta$) cá»§a mÃ´ hÃ¬nh, ta rÃºt ra cÃ¡c insight quan trá»ng:

1.  **Vá»‹ trÃ­ lÃ  quan trá»ng nháº¥t:**
    - `neighbourhood_group_Manhattan` cÃ³ há»‡ sá»‘ dÆ°Æ¡ng lá»›n nháº¥t (+4.266), kháº³ng Ä‘á»‹nh Manhattan lÃ  khu vá»±c Ä‘áº¯t Ä‘á» nháº¥t.
    - `dist_to_center` cÃ³ há»‡ sá»‘ Ã¢m (-0.689), nghÄ©a lÃ  cÃ ng xa trung tÃ¢m, giÃ¡ cÃ ng giáº£m.
2.  **Loáº¡i phÃ²ng quyáº¿t Ä‘á»‹nh má»©c giÃ¡ sÃ n:**
    - CÃ¡c biáº¿n `room_type` (Shared room, Private room) cÃ³ há»‡ sá»‘ Ã¢m ráº¥t lá»›n so vá»›i `Entire home/apt` (Ä‘Æ°á»£c áº©n trong intercept hoáº·c so sÃ¡nh tÆ°Æ¡ng Ä‘á»‘i), cho tháº¥y thuÃª nguyÃªn cÄƒn Ä‘áº¯t hÆ¡n nhiá»u so vá»›i thuÃª phÃ²ng láº».
3.  **TÃ­nh kháº£ dá»¥ng:**
    - `availability_365` cÃ³ há»‡ sá»‘ dÆ°Æ¡ng (+0.342), gá»£i Ã½ ráº±ng cÃ¡c cÄƒn há»™ chuyÃªn nghiá»‡p (trá»‘ng quanh nÄƒm Ä‘á»ƒ cho thuÃª) thÆ°á»ng cÃ³ giÃ¡ cao hÆ¡n cÃ¡c cÄƒn há»™ chá»‰ cho thuÃª ngáº¯n háº¡n/thá»i vá»¥.

#### So sÃ¡nh Linear Regression vs Lasso
- **Hiá»‡u nÄƒng:** Hai mÃ´ hÃ¬nh cho káº¿t quáº£ tÆ°Æ¡ng Ä‘Æ°Æ¡ng nhau (RÂ² ~ 0.55).
- **Lá»±a chá»n:**
    - **Linear Regression** Ä‘Æ°á»£c chá»n lÃ m mÃ´ hÃ¬nh cuá»‘i cÃ¹ng vÃ¬ tÃ­nh Ä‘Æ¡n giáº£n vÃ  khÃ´ng cáº§n tinh chá»‰nh tham sá»‘ $\alpha$ phá»©c táº¡p mÃ  váº«n Ä‘áº¡t hiá»‡u quáº£ cao.
    - **Lasso** há»¯u Ã­ch trong viá»‡c xÃ¡c Ä‘á»‹nh cÃ¡c Ä‘áº·c trÆ°ng thá»«a (Ä‘Æ°a há»‡ sá»‘ vá» 0), nhÆ°ng trong táº­p dá»¯ liá»‡u nÃ y, háº§u háº¿t cÃ¡c Ä‘áº·c trÆ°ng Ä‘Ã£ chá»n lá»c Ä‘á»u cÃ³ Ã½ nghÄ©a thá»‘ng kÃª.

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Dá»¯ liá»‡u thÃ´ (AB_NYC_2019.csv)
â”‚   â””â”€â”€ processed/          # Dá»¯ liá»‡u Ä‘Ã£ qua xá»­ lÃ½ (train/test features)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb  # EDA: PhÃ¢n tÃ­ch phÃ¢n phá»‘i, báº£n Ä‘á»“, tÆ°Æ¡ng quan
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb     # Pipeline: Cleaning, Encoding, Scaling
â”‚   â””â”€â”€ 03_modeling.ipynb          # Modeling: Linear/Lasso from scratch, CV, Evaluation
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_processing.py  # CÃ¡c hÃ m tiá»‡n Ã­ch xá»­ lÃ½ dá»¯ liá»‡u
â”‚   â”œâ”€â”€ models.py           # CÃ i Ä‘áº·t class LinearRegression, Lasso, KFold
â”‚   â””â”€â”€ visualization.py    # CÃ¡c hÃ m váº½ biá»ƒu Ä‘á»“
â”œâ”€â”€ README.md               # TÃ i liá»‡u bÃ¡o cÃ¡o dá»± Ã¡n
â””â”€â”€ requirements.txt        # Danh sÃ¡ch thÆ° viá»‡n phá»¥ thuá»™c
```

---

## ğŸ§© Challenges & Solutions

### 1. Vectorization vá»›i NumPy
- **KhÃ³ khÄƒn:** Chuyá»ƒn Ä‘á»•i cÃ¡c cÃ´ng thá»©c toÃ¡n há»c (nhÆ° Coordinate Descent) tá»« dáº¡ng vÃ²ng láº·p (for-loop) sang dáº¡ng vector hÃ³a Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ tÃ­nh toÃ¡n trÃªn táº­p dá»¯ liá»‡u lá»›n. Viá»‡c dÃ¹ng vÃ²ng láº·p trong Python ráº¥t cháº­m.
- **Giáº£i phÃ¡p:**
  - Táº­n dá»¥ng triá»‡t Ä‘á»ƒ **Broadcasting** cá»§a NumPy Ä‘á»ƒ thá»±c hiá»‡n phÃ©p tÃ­nh trÃªn toÃ n bá»™ máº£ng mÃ  khÃ´ng cáº§n loop.
  - Sá»­ dá»¥ng cÃ¡c phÃ©p toÃ¡n ma tráº­n tá»‘i Æ°u (`@` cho nhÃ¢n ma tráº­n, `np.sum`, `np.where`).
  - Pre-compute (tÃ­nh trÆ°á»›c) cÃ¡c giÃ¡ trá»‹ khÃ´ng Ä‘á»•i (nhÆ° $X^T X$ hoáº·c $||x_j||^2$) bÃªn ngoÃ i vÃ²ng láº·p tá»‘i Æ°u.

### 2. Xá»­ lÃ½ biáº¿n phÃ¢n loáº¡i nhiá»u giÃ¡ trá»‹ (High Cardinality)
- **KhÃ³ khÄƒn:** Cá»™t `neighbourhood` cÃ³ hÆ¡n 200 giÃ¡ trá»‹ khÃ¡c nhau. Náº¿u sá»­ dá»¥ng One-Hot Encoding thÃ´ng thÆ°á»ng sáº½ táº¡o ra hÆ¡n 200 cá»™t má»›i, lÃ m ma tráº­n Ä‘áº·c trÆ°ng trá»Ÿ nÃªn ráº¥t thÆ°a (sparse) vÃ  tÄƒng chi phÃ­ tÃ­nh toÃ¡n, Ä‘á»“ng thá»i dá»… gÃ¢y overfitting.
- **Giáº£i phÃ¡p:** Ãp dá»¥ng **Target Encoding** káº¿t há»£p **Smoothing**. Thay vÃ¬ táº¡o cá»™t má»›i, ta thay tháº¿ giÃ¡ trá»‹ cá»§a `neighbourhood` báº±ng giÃ¡ trung bÃ¬nh cá»§a má»¥c tiÃªu (`price`) táº¡i khu vá»±c Ä‘Ã³, cÃ³ Ä‘iá»u chá»‰nh (smoothing) Ä‘á»ƒ trÃ¡nh nhiá»…u á»Ÿ cÃ¡c khu vá»±c Ã­t dá»¯ liá»‡u.

### 3. á»”n Ä‘á»‹nh sá»‘ há»c (Numerical Stability)
- **KhÃ³ khÄƒn:** Khi tÃ­nh toÃ¡n nghá»‹ch Ä‘áº£o ma tráº­n $(X^T X)^{-1}$ trong Linear Regression, náº¿u ma tráº­n $X^T X$ gáº§n suy biáº¿n (singular) hoáº·c cÃ³ Ä‘iá»u kiá»‡n sá»‘ (condition number) lá»›n, káº¿t quáº£ sáº½ ráº¥t thiáº¿u chÃ­nh xÃ¡c.
- **Giáº£i phÃ¡p:** Thay vÃ¬ tÃ­nh nghá»‹ch Ä‘áº£o trá»±c tiáº¿p báº±ng `np.linalg.inv`, sá»­ dá»¥ng `np.linalg.solve` Ä‘á»ƒ giáº£i há»‡ phÆ°Æ¡ng trÃ¬nh tuyáº¿n tÃ­nh, giÃºp thuáº­t toÃ¡n á»•n Ä‘á»‹nh vÃ  chÃ­nh xÃ¡c hÆ¡n.

---

## ğŸ”® Future Improvements

1.  **Má»Ÿ rá»™ng mÃ´ hÃ¬nh:**
    - Thá»­ nghiá»‡m cÃ¡c mÃ´ hÃ¬nh phi tuyáº¿n tÃ­nh (Non-linear) nhÆ° **Decision Tree**, **Random Forest** hoáº·c **Gradient Boosting** (tá»± cÃ i Ä‘áº·t) Ä‘á»ƒ báº¯t Ä‘Æ°á»£c cÃ¡c má»‘i quan há»‡ phá»©c táº¡p hÆ¡n mÃ  mÃ´ hÃ¬nh tuyáº¿n tÃ­nh bá» qua.
    - CÃ i Ä‘áº·t thÃªm **Ridge Regression** (L2 Regularization) vÃ  **Elastic Net** (káº¿t há»£p L1 & L2).

2.  **Cáº£i thiá»‡n dá»¯ liá»‡u:**
    - TÃ­ch há»£p thÃªm dá»¯ liá»‡u bÃªn ngoÃ i (External Data) nhÆ°: khoáº£ng cÃ¡ch Ä‘áº¿n tráº¡m tÃ u Ä‘iá»‡n ngáº§m gáº§n nháº¥t, chá»‰ sá»‘ an ninh khu vá»±c, hoáº·c khoáº£ng cÃ¡ch Ä‘áº¿n cÃ¡c Ä‘iá»ƒm du lá»‹ch ná»•i tiáº¿ng khÃ¡c ngoÃ i Times Square.
    - Sá»­ dá»¥ng NLP Ä‘á»ƒ phÃ¢n tÃ­ch ná»™i dung review hoáº·c tÃªn listing (`name`) Ä‘á»ƒ trÃ­ch xuáº¥t thÃªm Ä‘áº·c trÆ°ng (vÃ­ dá»¥: "luxury", "cozy", "view").

3.  **á»¨ng dá»¥ng:**
    - XÃ¢y dá»±ng má»™t Web App Ä‘Æ¡n giáº£n (sá»­ dá»¥ng Streamlit hoáº·c Flask) cho phÃ©p ngÆ°á»i dÃ¹ng nháº­p thÃ´ng tin cÄƒn há»™ vÃ  nháº­n dá»± Ä‘oÃ¡n giÃ¡ ngay láº­p tá»©c.
    - Triá»ƒn khai API Ä‘á»ƒ tÃ­ch há»£p vÃ o cÃ¡c há»‡ thá»‘ng khÃ¡c.

---

## ğŸ‘¥ Contributors

**Shinoaki0145**
- **Role:** Data Scientist & ML Engineer
- **Github:** [Shinoaki0145](https://github.com/Shinoaki0145)

---

## ğŸ“œ License
This project is licensed under the MIT License - see the LICENSE file for details.
